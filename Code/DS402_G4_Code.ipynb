{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===========================================\n",
        "# Early Stage Diabetes Risk Prediction Project\n",
        "# ANN + Baselines (LR, SVM, RF, KNN) with CV, val-threshold tuning, calibration\n",
        "# ===========================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_STATE = 42\n",
        "random.seed(RANDOM_STATE)\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
        "    classification_report, confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay\n",
        ")\n",
        "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# TensorFlow / Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ],
      "metadata": {
        "id": "FBBbd7BuGrni"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "CSV_PATH = '/content/dataset.csv'  # set to path\n",
        "RESULTS_DIR = 'results_diabetes'\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "N_SPLITS = 5\n"
      ],
      "metadata": {
        "id": "5wFCI4pLHTMy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Load & Preprocess\n",
        "# -----------------------------\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "yes_no_cols = [\n",
        "    'Polyuria','Polydipsia','sudden weight loss','weakness','Polyphagia',\n",
        "    'Genital thrush','visual blurring','Itching','Irritability','delayed healing',\n",
        "    'partial paresis','muscle stiffness','Alopecia','Obesity'\n",
        "]\n",
        "\n",
        "# Map Yes/No → 1/0 (robust to whitespace/case)\n",
        "for c in yes_no_cols:\n",
        "    df[c] = (df[c].astype(str).str.strip().str.title()\n",
        "             .map({'Yes': 1, 'No': 0}))\n",
        "\n",
        "df['Gender'] = (df['Gender'].astype(str).str.strip().str.title()\n",
        "                .map({'Male': 1, 'Female': 0}))\n",
        "df['class']  = (df['class'].astype(str).str.strip().str.title()\n",
        "                .map({'Positive': 1, 'Negative': 0}))\n",
        "\n",
        "# Sanity check\n",
        "missing = df[yes_no_cols + ['Gender','class']].isna().sum().sum()\n",
        "if missing != 0:\n",
        "    raise ValueError(f\"Found {missing} missing values after mapping—clean the data before proceeding.\")\n",
        "\n",
        "X = df.drop(columns=['class'])\n",
        "y = df['class']\n",
        "\n",
        "num_cols = ['Age']\n",
        "bin_cols = [c for c in X.columns if c not in num_cols]\n",
        "\n",
        "# Train/Val/Test split\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.20, stratify=y_train_full, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# ColumnTransformer: scale Age only, passthrough binaries\n",
        "ct = ColumnTransformer(\n",
        "    [('num', StandardScaler(), num_cols), ('bin', 'passthrough', bin_cols)],\n",
        "    remainder='drop'\n",
        ")\n"
      ],
      "metadata": {
        "id": "--OKoIWDHTTf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def evaluate_model(name: str, y_true, y_pred, y_score) -> Dict:\n",
        "    \"\"\"Return metrics dict; y_score is prob or decision function for ROC-AUC.\"\"\"\n",
        "    return {\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'Precision': precision_score(y_true, y_pred),\n",
        "        'Recall': recall_score(y_true, y_pred),\n",
        "        'F1': f1_score(y_true, y_pred),\n",
        "        'ROC_AUC': roc_auc_score(y_true, y_score)\n",
        "    }\n",
        "\n",
        "def select_threshold_with_constraints(\n",
        "    y_true: np.ndarray,\n",
        "    y_score: np.ndarray,\n",
        "    target_recall: float = 0.98,\n",
        "    min_precision: float = 0.95\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Choose threshold on validation predictions to achieve recall >= target_recall\n",
        "    and precision >= min_precision. If no candidate exists, fall back to max F1.\n",
        "    \"\"\"\n",
        "    from sklearn.metrics import precision_recall_curve\n",
        "    prec, rec, thr = precision_recall_curve(y_true, y_score)\n",
        "    candidates = [(p, r, t, (2*p*r)/(p+r+1e-12))\n",
        "                  for p, r, t in zip(prec, rec, thr)\n",
        "                  if (r >= target_recall and p >= min_precision)]\n",
        "    if candidates:\n",
        "        best = max(candidates, key=lambda x: x[3])  # best F1 among candidates\n",
        "        return best[2]\n",
        "    # fallback to max F1\n",
        "    f1 = 2*prec*rec/(prec+rec+1e-12)\n",
        "    idx = np.argmax(f1)\n",
        "    return thr[idx] if idx < len(thr) else 0.5\n",
        "\n",
        "def plot_ann_diagnostics(y_true, y_score, y_pred, out_dir: str):\n",
        "    # ROC\n",
        "    fig_roc, ax_roc = plt.subplots(figsize=(6,5))\n",
        "    RocCurveDisplay.from_predictions(y_true, y_score, ax=ax_roc)\n",
        "    ax_roc.set_title('ANN ROC Curve (Test)')\n",
        "    fig_roc.tight_layout()\n",
        "    fig_roc.savefig(os.path.join(out_dir, 'ann_roc.png'), dpi=200)\n",
        "    plt.close(fig_roc)\n",
        "\n",
        "    # Precision-Recall\n",
        "    fig_pr, ax_pr = plt.subplots(figsize=(6,5))\n",
        "    PrecisionRecallDisplay.from_predictions(y_true, y_score, ax=ax_pr)\n",
        "    ax_pr.set_title('ANN Precision-Recall Curve (Test)')\n",
        "    fig_pr.tight_layout()\n",
        "    fig_pr.savefig(os.path.join(out_dir, 'ann_pr.png'), dpi=200)\n",
        "    plt.close(fig_pr)\n",
        "\n",
        "    # Calibration / Reliability\n",
        "    prob_true, prob_pred = calibration_curve(y_true, y_score, n_bins=10, strategy='uniform')\n",
        "    fig_cal, ax_cal = plt.subplots(figsize=(6,5))\n",
        "    ax_cal.plot(prob_pred, prob_true, marker='o')\n",
        "    ax_cal.plot([0,1],[0,1], '--', color='gray')\n",
        "    ax_cal.set_xlabel('Predicted probability (mean per bin)')\n",
        "    ax_cal.set_ylabel('Observed frequency')\n",
        "    ax_cal.set_title('ANN Reliability Diagram (Test)')\n",
        "    fig_cal.tight_layout()\n",
        "    fig_cal.savefig(os.path.join(out_dir, 'ann_calibration.png'), dpi=200)\n",
        "    plt.close(fig_cal)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    fig_cm, ax_cm = plt.subplots(figsize=(5,4))\n",
        "    im = ax_cm.imshow(cm, cmap='Blues')\n",
        "    ax_cm.set_xticks([0,1]); ax_cm.set_yticks([0,1])\n",
        "    ax_cm.set_xticklabels(['Negative','Positive'])\n",
        "    ax_cm.set_yticklabels(['Negative','Positive'])\n",
        "    for (i,j), val in np.ndenumerate(cm):\n",
        "        ax_cm.text(j, i, f'{val}', ha='center', va='center', color='black')\n",
        "    ax_cm.set_title('ANN Confusion Matrix (Test)')\n",
        "    ax_cm.set_xlabel('Predicted'); ax_cm.set_ylabel('True')\n",
        "    fig_cm.colorbar(im, ax=ax_cm)\n",
        "    fig_cm.tight_layout()\n",
        "    fig_cm.savefig(os.path.join(out_dir, 'ann_confusion_matrix.png'), dpi=200)\n",
        "    plt.close(fig_cm)\n"
      ],
      "metadata": {
        "id": "V2IvR9eTHTZ8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Baselines: 5-fold CV (mean ± std)\n",
        "# For CV: use SVC(probability=True) to avoid nested CV inside calibration.\n",
        "# -----------------------------\n",
        "baselines_cv = []\n",
        "\n",
        "pipe_lr = Pipeline([('prep', ct), ('clf', LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))])\n",
        "pipe_svm_cv = Pipeline([('prep', ct), ('clf', SVC(kernel='rbf', probability=True, random_state=RANDOM_STATE))])\n",
        "pipe_rf = Pipeline([('prep', ct), ('clf', RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE))])\n",
        "pipe_knn = Pipeline([('prep', ct), ('clf', KNeighborsClassifier(n_neighbors=5))])\n",
        "\n",
        "def cv_scores(name, estimator, X, y):\n",
        "    scoring = ['accuracy','precision','recall','f1','roc_auc']\n",
        "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
        "    out = cross_validate(estimator, X, y, scoring=scoring, cv=skf, n_jobs=-1, return_train_score=False)\n",
        "    return {\n",
        "        'Model': name,\n",
        "        **{f'{m}_mean': float(np.mean(out[f'test_{m}'])) for m in scoring},\n",
        "        **{f'{m}_std' : float(np.std(out[f'test_{m}']))  for m in scoring}\n",
        "    }\n",
        "\n",
        "baselines_cv.append(cv_scores(\"Logistic Regression\", pipe_lr, X, y))\n",
        "baselines_cv.append(cv_scores(\"SVM (RBF)\",           pipe_svm_cv, X, y))\n",
        "baselines_cv.append(cv_scores(\"Random Forest\",       pipe_rf, X, y))\n",
        "baselines_cv.append(cv_scores(\"KNN (k=5)\",           pipe_knn, X, y))\n",
        "\n",
        "cv_df = pd.DataFrame(baselines_cv)\n",
        "cv_df.to_excel(os.path.join(RESULTS_DIR, 'baselines_cv_results.xlsx'), index=False)\n"
      ],
      "metadata": {
        "id": "iot9_frvHTf1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Fit baselines on train_full and evaluate on test (one-shot)\n",
        "# SVM on test: calibrated probabilities (isotonic).\n",
        "# -----------------------------\n",
        "def fit_and_eval_on_test(name, estimator):\n",
        "    estimator.fit(X_train_full, y_train_full)\n",
        "    # proba or decision score\n",
        "    if hasattr(estimator, 'predict_proba'):\n",
        "        y_score = estimator.predict_proba(X_test)[:, 1]\n",
        "    elif hasattr(estimator, 'decision_function'):\n",
        "        y_score = estimator.decision_function(X_test)\n",
        "    else:\n",
        "        raise ValueError(f\"{name} does not support probability/decision scores.\")\n",
        "    y_pred = estimator.predict(X_test)\n",
        "    return evaluate_model(name, y_test, y_pred, y_score)\n",
        "\n",
        "test_results_map = {}\n",
        "test_results_map[\"Logistic Regression\"] = fit_and_eval_on_test(\"Logistic Regression\", pipe_lr)\n",
        "test_results_map[\"Random Forest\"]       = fit_and_eval_on_test(\"Random Forest\", pipe_rf)\n",
        "test_results_map[\"KNN (k=5)\"]           = fit_and_eval_on_test(\"KNN (k=5)\", pipe_knn)\n",
        "\n",
        "# SVM (calibrated) — fit separately and evaluate\n",
        "svm_base = Pipeline([('prep', ct), ('clf', SVC(kernel='rbf', probability=False, random_state=RANDOM_STATE))])\n",
        "svm_cal  = CalibratedClassifierCV(svm_base, cv=N_SPLITS, method='isotonic')\n",
        "svm_cal.fit(X_train_full, y_train_full)\n",
        "y_score_svm = svm_cal.predict_proba(X_test)[:,1]\n",
        "y_pred_svm  = svm_cal.predict(X_test)\n",
        "test_results_map[\"SVM (RBF, calibrated)\"] = evaluate_model(\"SVM (RBF, calibrated)\", y_test, y_pred_svm, y_score_svm)\n"
      ],
      "metadata": {
        "id": "gNZwzT3-HSEv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# ANN: CV (5-fold) for robustness\n",
        "# -----------------------------\n",
        "def ann_build(input_dim: int) -> tf.keras.Model:\n",
        "    tf.random.set_seed(RANDOM_STATE)\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.30),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dropout(0.20),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
        "    return model\n",
        "\n",
        "def ann_cv_scores(X: pd.DataFrame, y: pd.Series, n_splits=5) -> Dict:\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "    metrics = {'accuracy':[], 'precision':[], 'recall':[], 'f1':[], 'roc_auc':[]}\n",
        "    for train_idx, test_idx in skf.split(X, y):\n",
        "        X_tr, X_te = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_tr, y_te = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        # Fit ColumnTransformer on training fold\n",
        "        ct_fold = ColumnTransformer(\n",
        "            [('num', StandardScaler(), num_cols), ('bin', 'passthrough', bin_cols)],\n",
        "            remainder='drop'\n",
        "        )\n",
        "        X_tr_s = ct_fold.fit_transform(X_tr)\n",
        "        X_te_s = ct_fold.transform(X_te)\n",
        "\n",
        "        # Internal validation split for early-stopping\n",
        "        X_tr_s2, X_val_s2, y_tr2, y_val2 = train_test_split(\n",
        "            X_tr_s, y_tr, test_size=0.2, stratify=y_tr, random_state=RANDOM_STATE\n",
        "        )\n",
        "\n",
        "        model = ann_build(X_tr_s.shape[1])\n",
        "        early = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "        model.fit(X_tr_s2, y_tr2, validation_data=(X_val_s2, y_val2),\n",
        "                  epochs=100, batch_size=32, callbacks=[early], verbose=0)\n",
        "\n",
        "        # Threshold on validation = max F1 (fold-wise)\n",
        "        y_val_score = model.predict(X_val_s2).ravel()\n",
        "        from sklearn.metrics import precision_recall_curve\n",
        "        prec, rec, thr = precision_recall_curve(y_val2, y_val_score)\n",
        "        f1 = 2*prec*rec/(prec+rec+1e-12)\n",
        "        idx = np.argmax(f1)\n",
        "        thr_best = thr[idx] if idx < len(thr) else 0.5\n",
        "\n",
        "        # Evaluate on fold test\n",
        "        y_te_score = model.predict(X_te_s).ravel()\n",
        "        y_te_pred  = (y_te_score >= thr_best).astype(int)\n",
        "\n",
        "        metrics['accuracy'].append(accuracy_score(y_te, y_te_pred))\n",
        "        metrics['precision'].append(precision_score(y_te, y_te_pred))\n",
        "        metrics['recall'].append(recall_score(y_te, y_te_pred))\n",
        "        metrics['f1'].append(f1_score(y_te, y_te_pred))\n",
        "        metrics['roc_auc'].append(roc_auc_score(y_te, y_te_score))\n",
        "\n",
        "    return {\n",
        "        'Model': 'ANN (CV)',\n",
        "        'accuracy_mean': float(np.mean(metrics['accuracy'])),\n",
        "        'accuracy_std' : float(np.std(metrics['accuracy'])),\n",
        "        'precision_mean': float(np.mean(metrics['precision'])),\n",
        "        'precision_std' : float(np.std(metrics['precision'])),\n",
        "        'recall_mean': float(np.mean(metrics['recall'])),\n",
        "        'recall_std' : float(np.std(metrics['recall'])),\n",
        "        'f1_mean': float(np.mean(metrics['f1'])),\n",
        "        'f1_std' : float(np.std(metrics['f1'])),\n",
        "        'roc_auc_mean': float(np.mean(metrics['roc_auc'])),\n",
        "        'roc_auc_std' : float(np.std(metrics['roc_auc']))\n",
        "    }\n",
        "\n",
        "# Compute ANN CV metrics and append to CV table\n",
        "ann_cv = ann_cv_scores(X, y, n_splits=N_SPLITS)\n",
        "cv_df = pd.concat([cv_df, pd.DataFrame([ann_cv])], ignore_index=True)\n",
        "cv_df.to_excel(os.path.join(RESULTS_DIR, 'baselines_plus_ann_cv_results.xlsx'), index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5bKBTkCeI7kS",
        "outputId": "d104e1b7-e778-40d1-e351-4696c568d4ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ed262e62480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ed262c27d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ANN: Final training on Train with Validation\n",
        "# - Isotonic calibration of probabilities\n",
        "# - Threshold selection with clinical constraints\n",
        "# -----------------------------\n",
        "# Fit transformer on training (not on validation/test)\n",
        "ct_ann = ColumnTransformer(\n",
        "    [('num', StandardScaler(), num_cols), ('bin', 'passthrough', bin_cols)],\n",
        "    remainder='drop'\n",
        ")\n",
        "X_train_s = ct_ann.fit_transform(X_train)\n",
        "X_val_s   = ct_ann.transform(X_val)\n",
        "X_test_s  = ct_ann.transform(X_test)\n",
        "\n",
        "model_ann = ann_build(X_train_s.shape[1])\n",
        "early = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "history = model_ann.fit(X_train_s, y_train, validation_data=(X_val_s, y_val),\n",
        "                        epochs=100, batch_size=32, callbacks=[early], verbose=1)\n",
        "\n",
        "# Raw validation probabilities\n",
        "y_val_score_raw = model_ann.predict(X_val_s).ravel()\n",
        "\n",
        "# Optional: Calibrate ANN probabilities via Isotonic Regression\n",
        "iso = IsotonicRegression(out_of_bounds='clip')\n",
        "iso.fit(y_val_score_raw, y_val.astype(int))\n",
        "y_val_score_cal = iso.predict(y_val_score_raw)\n",
        "\n",
        "# Choose threshold on calibrated validation scores with constraints\n",
        "best_thr = select_threshold_with_constraints(\n",
        "    y_true=y_val,\n",
        "    y_score=y_val_score_cal,\n",
        "    target_recall=0.98,\n",
        "    min_precision=0.95\n",
        ")\n",
        "\n",
        "# Test evaluation using calibrated probabilities and chosen threshold\n",
        "y_test_score_raw = model_ann.predict(X_test_s).ravel()\n",
        "y_test_score_cal = iso.predict(y_test_score_raw)  # calibrated\n",
        "y_test_pred      = (y_test_score_cal >= best_thr).astype(int)\n",
        "\n",
        "ann_metrics = evaluate_model(\"ANN (thr tuned on val; calibrated)\", y_test, y_test_pred, y_test_score_cal)\n",
        "ann_report  = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "ann_cm      = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "# Plots\n",
        "plot_ann_diagnostics(y_test, y_test_score_cal, y_test_pred, out_dir=RESULTS_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YBSu5yn2I-fD",
        "outputId": "7242f379-dbc3-42b2-b725-86072e895faa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.4454 - auc: 0.5622 - loss: 0.7252 - val_accuracy: 0.6786 - val_auc: 0.7575 - val_loss: 0.6673\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5121 - auc: 0.5781 - loss: 0.6841 - val_accuracy: 0.7024 - val_auc: 0.8302 - val_loss: 0.6252\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6664 - auc: 0.6908 - loss: 0.6453 - val_accuracy: 0.6905 - val_auc: 0.8627 - val_loss: 0.5968\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6957 - auc: 0.7456 - loss: 0.6051 - val_accuracy: 0.7024 - val_auc: 0.8885 - val_loss: 0.5729\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7047 - auc: 0.7641 - loss: 0.5883 - val_accuracy: 0.7262 - val_auc: 0.9087 - val_loss: 0.5502\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7292 - auc: 0.8116 - loss: 0.5598 - val_accuracy: 0.8333 - val_auc: 0.9303 - val_loss: 0.5248\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7617 - auc: 0.8702 - loss: 0.5200 - val_accuracy: 0.8333 - val_auc: 0.9345 - val_loss: 0.4955\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7896 - auc: 0.8903 - loss: 0.4887 - val_accuracy: 0.8333 - val_auc: 0.9441 - val_loss: 0.4654\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8224 - auc: 0.8844 - loss: 0.4838 - val_accuracy: 0.8333 - val_auc: 0.9486 - val_loss: 0.4343\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8298 - auc: 0.8907 - loss: 0.4505 - val_accuracy: 0.8690 - val_auc: 0.9498 - val_loss: 0.4037\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8651 - auc: 0.9326 - loss: 0.4128 - val_accuracy: 0.8690 - val_auc: 0.9534 - val_loss: 0.3734\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8781 - auc: 0.9541 - loss: 0.3617 - val_accuracy: 0.8810 - val_auc: 0.9558 - val_loss: 0.3453\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8704 - auc: 0.9485 - loss: 0.3471 - val_accuracy: 0.8929 - val_auc: 0.9573 - val_loss: 0.3231\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8853 - auc: 0.9495 - loss: 0.3239 - val_accuracy: 0.9048 - val_auc: 0.9564 - val_loss: 0.3070\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8950 - auc: 0.9577 - loss: 0.2950 - val_accuracy: 0.9048 - val_auc: 0.9558 - val_loss: 0.2944\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9079 - auc: 0.9647 - loss: 0.2673 - val_accuracy: 0.8929 - val_auc: 0.9567 - val_loss: 0.2825\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8988 - auc: 0.9622 - loss: 0.2711 - val_accuracy: 0.8929 - val_auc: 0.9579 - val_loss: 0.2739\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9210 - auc: 0.9702 - loss: 0.2521 - val_accuracy: 0.9048 - val_auc: 0.9567 - val_loss: 0.2679\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9009 - auc: 0.9608 - loss: 0.2627 - val_accuracy: 0.9048 - val_auc: 0.9585 - val_loss: 0.2711\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9231 - auc: 0.9808 - loss: 0.2022 - val_accuracy: 0.9048 - val_auc: 0.9591 - val_loss: 0.2661\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9165 - auc: 0.9697 - loss: 0.2338 - val_accuracy: 0.9048 - val_auc: 0.9591 - val_loss: 0.2602\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9222 - auc: 0.9761 - loss: 0.2081 - val_accuracy: 0.9048 - val_auc: 0.9603 - val_loss: 0.2596\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9173 - auc: 0.9677 - loss: 0.2360 - val_accuracy: 0.9048 - val_auc: 0.9582 - val_loss: 0.2581\n",
            "Epoch 24/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9360 - auc: 0.9777 - loss: 0.2012 - val_accuracy: 0.9048 - val_auc: 0.9600 - val_loss: 0.2506\n",
            "Epoch 25/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9165 - auc: 0.9716 - loss: 0.2134 - val_accuracy: 0.9048 - val_auc: 0.9603 - val_loss: 0.2467\n",
            "Epoch 26/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9168 - auc: 0.9685 - loss: 0.2154 - val_accuracy: 0.8929 - val_auc: 0.9615 - val_loss: 0.2445\n",
            "Epoch 27/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9249 - auc: 0.9752 - loss: 0.1976 - val_accuracy: 0.8929 - val_auc: 0.9621 - val_loss: 0.2426\n",
            "Epoch 28/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9345 - auc: 0.9804 - loss: 0.1894 - val_accuracy: 0.8929 - val_auc: 0.9621 - val_loss: 0.2392\n",
            "Epoch 29/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9333 - auc: 0.9803 - loss: 0.1729 - val_accuracy: 0.8929 - val_auc: 0.9621 - val_loss: 0.2365\n",
            "Epoch 30/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9437 - auc: 0.9776 - loss: 0.1909 - val_accuracy: 0.8929 - val_auc: 0.9618 - val_loss: 0.2361\n",
            "Epoch 31/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9246 - auc: 0.9775 - loss: 0.1889 - val_accuracy: 0.9048 - val_auc: 0.9615 - val_loss: 0.2370\n",
            "Epoch 32/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9556 - auc: 0.9849 - loss: 0.1623 - val_accuracy: 0.8929 - val_auc: 0.9651 - val_loss: 0.2338\n",
            "Epoch 33/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9477 - auc: 0.9821 - loss: 0.1734 - val_accuracy: 0.8929 - val_auc: 0.9663 - val_loss: 0.2285\n",
            "Epoch 34/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9251 - auc: 0.9848 - loss: 0.1712 - val_accuracy: 0.8929 - val_auc: 0.9672 - val_loss: 0.2305\n",
            "Epoch 35/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9506 - auc: 0.9853 - loss: 0.1472 - val_accuracy: 0.8929 - val_auc: 0.9672 - val_loss: 0.2284\n",
            "Epoch 36/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9326 - auc: 0.9819 - loss: 0.1695 - val_accuracy: 0.8929 - val_auc: 0.9684 - val_loss: 0.2245\n",
            "Epoch 37/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9460 - auc: 0.9886 - loss: 0.1331 - val_accuracy: 0.8929 - val_auc: 0.9709 - val_loss: 0.2211\n",
            "Epoch 38/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9501 - auc: 0.9854 - loss: 0.1490 - val_accuracy: 0.8929 - val_auc: 0.9700 - val_loss: 0.2218\n",
            "Epoch 39/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9692 - auc: 0.9875 - loss: 0.1383 - val_accuracy: 0.9048 - val_auc: 0.9687 - val_loss: 0.2247\n",
            "Epoch 40/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9640 - auc: 0.9880 - loss: 0.1303 - val_accuracy: 0.9048 - val_auc: 0.9697 - val_loss: 0.2220\n",
            "Epoch 41/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9396 - auc: 0.9888 - loss: 0.1386 - val_accuracy: 0.9048 - val_auc: 0.9706 - val_loss: 0.2171\n",
            "Epoch 42/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9560 - auc: 0.9885 - loss: 0.1390 - val_accuracy: 0.9048 - val_auc: 0.9706 - val_loss: 0.2179\n",
            "Epoch 43/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9543 - auc: 0.9916 - loss: 0.1279 - val_accuracy: 0.9048 - val_auc: 0.9703 - val_loss: 0.2185\n",
            "Epoch 44/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9661 - auc: 0.9905 - loss: 0.1303 - val_accuracy: 0.9048 - val_auc: 0.9709 - val_loss: 0.2186\n",
            "Epoch 45/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9809 - auc: 0.9969 - loss: 0.1012 - val_accuracy: 0.9048 - val_auc: 0.9718 - val_loss: 0.2171\n",
            "Epoch 46/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9413 - auc: 0.9906 - loss: 0.1279 - val_accuracy: 0.9286 - val_auc: 0.9715 - val_loss: 0.2125\n",
            "Epoch 47/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9527 - auc: 0.9883 - loss: 0.1282 - val_accuracy: 0.9286 - val_auc: 0.9718 - val_loss: 0.2099\n",
            "Epoch 48/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9739 - auc: 0.9889 - loss: 0.1316 - val_accuracy: 0.9286 - val_auc: 0.9736 - val_loss: 0.2095\n",
            "Epoch 49/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9602 - auc: 0.9902 - loss: 0.1184 - val_accuracy: 0.9286 - val_auc: 0.9736 - val_loss: 0.2113\n",
            "Epoch 50/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9717 - auc: 0.9906 - loss: 0.1153 - val_accuracy: 0.9286 - val_auc: 0.9745 - val_loss: 0.2094\n",
            "Epoch 51/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9642 - auc: 0.9928 - loss: 0.1109 - val_accuracy: 0.9286 - val_auc: 0.9754 - val_loss: 0.2074\n",
            "Epoch 52/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9776 - auc: 0.9939 - loss: 0.1019 - val_accuracy: 0.9286 - val_auc: 0.9754 - val_loss: 0.2075\n",
            "Epoch 53/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9536 - auc: 0.9940 - loss: 0.1061 - val_accuracy: 0.9286 - val_auc: 0.9751 - val_loss: 0.2098\n",
            "Epoch 54/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9543 - auc: 0.9940 - loss: 0.1040 - val_accuracy: 0.9286 - val_auc: 0.9745 - val_loss: 0.2131\n",
            "Epoch 55/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9732 - auc: 0.9948 - loss: 0.0987 - val_accuracy: 0.9286 - val_auc: 0.9748 - val_loss: 0.2133\n",
            "Epoch 56/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9723 - auc: 0.9955 - loss: 0.0900 - val_accuracy: 0.9286 - val_auc: 0.9748 - val_loss: 0.2108\n",
            "Epoch 57/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9696 - auc: 0.9921 - loss: 0.1055 - val_accuracy: 0.9286 - val_auc: 0.9751 - val_loss: 0.2076\n",
            "Epoch 58/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9419 - auc: 0.9911 - loss: 0.1199 - val_accuracy: 0.9286 - val_auc: 0.9754 - val_loss: 0.2045\n",
            "Epoch 59/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9781 - auc: 0.9963 - loss: 0.0835 - val_accuracy: 0.9286 - val_auc: 0.9751 - val_loss: 0.2054\n",
            "Epoch 60/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9586 - auc: 0.9940 - loss: 0.1048 - val_accuracy: 0.9286 - val_auc: 0.9751 - val_loss: 0.2064\n",
            "Epoch 61/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9828 - auc: 0.9978 - loss: 0.0752 - val_accuracy: 0.9286 - val_auc: 0.9751 - val_loss: 0.2073\n",
            "Epoch 62/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9556 - auc: 0.9914 - loss: 0.1096 - val_accuracy: 0.9286 - val_auc: 0.9757 - val_loss: 0.2049\n",
            "Epoch 63/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9668 - auc: 0.9958 - loss: 0.0907 - val_accuracy: 0.9286 - val_auc: 0.9757 - val_loss: 0.2027\n",
            "Epoch 64/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9749 - auc: 0.9967 - loss: 0.0791 - val_accuracy: 0.9286 - val_auc: 0.9760 - val_loss: 0.2015\n",
            "Epoch 65/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9737 - auc: 0.9941 - loss: 0.0946 - val_accuracy: 0.9286 - val_auc: 0.9760 - val_loss: 0.2026\n",
            "Epoch 66/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9579 - auc: 0.9944 - loss: 0.0980 - val_accuracy: 0.9286 - val_auc: 0.9760 - val_loss: 0.2037\n",
            "Epoch 67/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9727 - auc: 0.9954 - loss: 0.0837 - val_accuracy: 0.9286 - val_auc: 0.9760 - val_loss: 0.2039\n",
            "Epoch 68/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9665 - auc: 0.9940 - loss: 0.0971 - val_accuracy: 0.9286 - val_auc: 0.9766 - val_loss: 0.2014\n",
            "Epoch 69/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9879 - auc: 0.9969 - loss: 0.0729 - val_accuracy: 0.9286 - val_auc: 0.9766 - val_loss: 0.2008\n",
            "Epoch 70/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9678 - auc: 0.9958 - loss: 0.0872 - val_accuracy: 0.9286 - val_auc: 0.9766 - val_loss: 0.2006\n",
            "Epoch 71/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9785 - auc: 0.9973 - loss: 0.0740 - val_accuracy: 0.9286 - val_auc: 0.9775 - val_loss: 0.1988\n",
            "Epoch 72/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9810 - auc: 0.9980 - loss: 0.0687 - val_accuracy: 0.9286 - val_auc: 0.9772 - val_loss: 0.1990\n",
            "Epoch 73/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9835 - auc: 0.9964 - loss: 0.0674 - val_accuracy: 0.9286 - val_auc: 0.9772 - val_loss: 0.2002\n",
            "Epoch 74/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9844 - auc: 0.9973 - loss: 0.0657 - val_accuracy: 0.9286 - val_auc: 0.9772 - val_loss: 0.1995\n",
            "Epoch 75/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9743 - auc: 0.9973 - loss: 0.0749 - val_accuracy: 0.9286 - val_auc: 0.9669 - val_loss: 0.1975\n",
            "Epoch 76/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9704 - auc: 0.9968 - loss: 0.0714 - val_accuracy: 0.9286 - val_auc: 0.9675 - val_loss: 0.1978\n",
            "Epoch 77/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9801 - auc: 0.9980 - loss: 0.0596 - val_accuracy: 0.9286 - val_auc: 0.9684 - val_loss: 0.2001\n",
            "Epoch 78/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9684 - auc: 0.9970 - loss: 0.0700 - val_accuracy: 0.9286 - val_auc: 0.9694 - val_loss: 0.2010\n",
            "Epoch 79/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9776 - auc: 0.9959 - loss: 0.0721 - val_accuracy: 0.9286 - val_auc: 0.9694 - val_loss: 0.1987\n",
            "Epoch 80/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9916 - auc: 0.9978 - loss: 0.0574 - val_accuracy: 0.9286 - val_auc: 0.9700 - val_loss: 0.1994\n",
            "Epoch 81/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9764 - auc: 0.9973 - loss: 0.0698 - val_accuracy: 0.9286 - val_auc: 0.9700 - val_loss: 0.1983\n",
            "Epoch 82/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9854 - auc: 0.9979 - loss: 0.0635 - val_accuracy: 0.9286 - val_auc: 0.9703 - val_loss: 0.1965\n",
            "Epoch 83/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9915 - auc: 0.9985 - loss: 0.0605 - val_accuracy: 0.9286 - val_auc: 0.9700 - val_loss: 0.1981\n",
            "Epoch 84/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9855 - auc: 0.9980 - loss: 0.0615 - val_accuracy: 0.9286 - val_auc: 0.9703 - val_loss: 0.1993\n",
            "Epoch 85/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9886 - auc: 0.9973 - loss: 0.0561 - val_accuracy: 0.9286 - val_auc: 0.9712 - val_loss: 0.1960\n",
            "Epoch 86/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9900 - auc: 0.9993 - loss: 0.0481 - val_accuracy: 0.9286 - val_auc: 0.9712 - val_loss: 0.1943\n",
            "Epoch 87/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9769 - auc: 0.9987 - loss: 0.0576 - val_accuracy: 0.9286 - val_auc: 0.9724 - val_loss: 0.1943\n",
            "Epoch 88/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9849 - auc: 0.9977 - loss: 0.0651 - val_accuracy: 0.9286 - val_auc: 0.9721 - val_loss: 0.1978\n",
            "Epoch 89/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9922 - auc: 0.9992 - loss: 0.0494 - val_accuracy: 0.9286 - val_auc: 0.9727 - val_loss: 0.1992\n",
            "Epoch 90/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9858 - auc: 0.9995 - loss: 0.0453 - val_accuracy: 0.9286 - val_auc: 0.9733 - val_loss: 0.1998\n",
            "Epoch 91/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9872 - auc: 0.9989 - loss: 0.0517 - val_accuracy: 0.9286 - val_auc: 0.9730 - val_loss: 0.2003\n",
            "Epoch 92/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9911 - auc: 0.9987 - loss: 0.0540 - val_accuracy: 0.9286 - val_auc: 0.9736 - val_loss: 0.1979\n",
            "Epoch 93/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9809 - auc: 0.9982 - loss: 0.0575 - val_accuracy: 0.9286 - val_auc: 0.9736 - val_loss: 0.1940\n",
            "Epoch 94/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9865 - auc: 0.9986 - loss: 0.0499 - val_accuracy: 0.9286 - val_auc: 0.9742 - val_loss: 0.1942\n",
            "Epoch 95/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9813 - auc: 0.9992 - loss: 0.0462 - val_accuracy: 0.9286 - val_auc: 0.9739 - val_loss: 0.1949\n",
            "Epoch 96/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9828 - auc: 0.9983 - loss: 0.0496 - val_accuracy: 0.9286 - val_auc: 0.9745 - val_loss: 0.1913\n",
            "Epoch 97/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9883 - auc: 0.9989 - loss: 0.0458 - val_accuracy: 0.9286 - val_auc: 0.9754 - val_loss: 0.1911\n",
            "Epoch 98/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9908 - auc: 0.9992 - loss: 0.0413 - val_accuracy: 0.9286 - val_auc: 0.9751 - val_loss: 0.1925\n",
            "Epoch 99/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9796 - auc: 0.9991 - loss: 0.0555 - val_accuracy: 0.9286 - val_auc: 0.9757 - val_loss: 0.1907\n",
            "Epoch 100/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9837 - auc: 0.9987 - loss: 0.0529 - val_accuracy: 0.9286 - val_auc: 0.9763 - val_loss: 0.1911\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Feature importance (RF) for interpretability\n",
        "# -----------------------------\n",
        "pipe_rf.fit(X_train_full, y_train_full)\n",
        "perm = permutation_importance(pipe_rf, X_test, y_test, n_repeats=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
        "fi = pd.DataFrame({\n",
        "    'feature': num_cols + bin_cols,\n",
        "    'mean_importance': perm.importances_mean,\n",
        "    'std_importance': perm.importances_std\n",
        "}).sort_values(by='mean_importance', ascending=False)\n",
        "fi.to_excel(os.path.join(RESULTS_DIR, 'rf_permutation_importance.xlsx'), index=False)\n",
        "\n",
        "# Top 10 (Quick Plot)\n",
        "top_n = 10\n",
        "fig_fi, ax_fi = plt.subplots(figsize=(8,5))\n",
        "fi.head(top_n).plot(kind='barh', x='feature', y='mean_importance',\n",
        "                    xerr=fi.head(top_n)['std_importance'], ax=ax_fi, color='teal')\n",
        "ax_fi.invert_yaxis()\n",
        "ax_fi.set_title('Random Forest Permutation Importance (Top 10)')\n",
        "ax_fi.set_xlabel('Mean decrease in score')\n",
        "fig_fi.tight_layout()\n",
        "fig_fi.savefig(os.path.join(RESULTS_DIR, 'rf_permutation_importance.png'), dpi=200)\n",
        "plt.close(fig_fi)\n"
      ],
      "metadata": {
        "id": "vhHxk3Q_JBgZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Save consolidated outputs\n",
        "# -----------------------------\n",
        "# CV results\n",
        "print(\"\\n=== Baselines + ANN (5-fold CV) mean±std ===\")\n",
        "print(cv_df[['Model','accuracy_mean','accuracy_std','precision_mean','precision_std',\n",
        "             'recall_mean','recall_std','f1_mean','f1_std','roc_auc_mean','roc_auc_std']])\n",
        "cv_df.to_excel(os.path.join(RESULTS_DIR, 'cv_summary.xlsx'), index=False)\n",
        "\n",
        "# Test-set table (one-shot fits) with idempotent dict\n",
        "test_results_map[\"SVM (RBF, calibrated)\"] = test_results_map.pop(\"SVM (RBF, calibrated)\") if \"SVM (RBF, calibrated)\" in test_results_map else evaluate_model(\"SVM (RBF, calibrated)\", y_test, y_pred_svm, y_score_svm)\n",
        "test_results_map[\"ANN (thr tuned on val; calibrated)\"] = ann_metrics\n",
        "test_df = pd.DataFrame(test_results_map.values()).sort_values(by='ROC_AUC', ascending=False)\n",
        "test_df['Notes'] = ''\n",
        "test_df.loc[test_df['Model'] == 'ANN (thr tuned on val; calibrated)',\n",
        "            'Notes'] = f'Calibrated (Isotonic); Threshold={best_thr:.4f} chosen on validation with recall≥0.98 & precision≥0.95'\n",
        "\n",
        "print(\"\\n=== Test-set comparison (one-shot fits) ===\")\n",
        "print(test_df)\n",
        "\n",
        "test_df.to_excel(os.path.join(RESULTS_DIR, 'test_set_comparison.xlsx'), index=False)\n",
        "\n",
        "# ANN details JSON\n",
        "ann_detail = {\n",
        "    'ann_metrics_test': ann_metrics,\n",
        "    'ann_threshold_validation': float(best_thr),\n",
        "    'ann_classification_report_test': ann_report,\n",
        "    'ann_confusion_matrix_test': ann_cm.tolist()\n",
        "}\n",
        "with open(os.path.join(RESULTS_DIR, 'ann_details.json'), 'w') as f:\n",
        "    json.dump(ann_detail, f, indent=2)\n",
        "\n",
        "# Class counts for the report\n",
        "print(\"\\n=== Class counts ===\")\n",
        "print(df['class'].value_counts())\n"
      ],
      "metadata": {
        "id": "gh-hwAsjJEJ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bd798c46-6464-44ae-8096-1498d288d055"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Baselines + ANN (5-fold CV) mean±std ===\n",
            "                 Model  accuracy_mean  accuracy_std  precision_mean  \\\n",
            "0  Logistic Regression       0.928846      0.011538        0.947398   \n",
            "1            SVM (RBF)       0.967308      0.007692        0.978064   \n",
            "2        Random Forest       0.982692      0.012756        0.987589   \n",
            "3            KNN (k=5)       0.913462      0.019231        0.969878   \n",
            "4             ANN (CV)       0.953846      0.016543        0.954437   \n",
            "\n",
            "   precision_std  recall_mean  recall_std   f1_mean    f1_std  roc_auc_mean  \\\n",
            "0       0.024740     0.937500    0.019764  0.941974  0.008981      0.976562   \n",
            "1       0.007215     0.968750    0.017116  0.973249  0.006626      0.997266   \n",
            "2       0.011422     0.984375    0.017116  0.985874  0.010516      0.998750   \n",
            "3       0.015251     0.887500    0.037500  0.926219  0.018024      0.978516   \n",
            "4       0.017853     0.971875    0.025000  0.962778  0.013500      0.989531   \n",
            "\n",
            "   roc_auc_std  \n",
            "0     0.009188  \n",
            "1     0.001694  \n",
            "2     0.001109  \n",
            "3     0.008328  \n",
            "4     0.009242  \n",
            "\n",
            "=== Test-set comparison (one-shot fits) ===\n",
            "                                Model  Accuracy  Precision    Recall  \\\n",
            "4  ANN (thr tuned on val; calibrated)  0.971154   0.955224  1.000000   \n",
            "1                       Random Forest  0.980769   0.984375  0.984375   \n",
            "3               SVM (RBF, calibrated)  0.990385   0.984615  1.000000   \n",
            "0                 Logistic Regression  0.942308   0.983333  0.921875   \n",
            "2                           KNN (k=5)  0.932692   0.983051  0.906250   \n",
            "\n",
            "         F1   ROC_AUC                                              Notes  \n",
            "4  0.977099  0.999219  Calibrated (Isotonic); Threshold=0.5000 chosen...  \n",
            "1  0.984375  0.998828                                                     \n",
            "3  0.992248  0.998437                                                     \n",
            "0  0.951613  0.990625                                                     \n",
            "2  0.943089  0.961523                                                     \n",
            "\n",
            "=== Class counts ===\n",
            "class\n",
            "1    320\n",
            "0    200\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}